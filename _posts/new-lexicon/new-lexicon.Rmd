---
title: "New Direction of Sentiment Analysis"
description: |
  Adding on to my initial sentiment analysis using new methods and dictionaries.
categories:
  - text as data
  - NYT text analysis project
author:
  - name: Kristina Becvar
    url: https://kbec19.github.io/NYT-Analysis/
    affiliation: UMass DACSS Program (My Academic Blog Link)
    affiliation_url: https://kristinabecvar.com
slug: new-lexicon
date: 2022-04-27
output:
  distill::distill_article:
    toc: true
    code_folding: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Using New Dictionaries

This time, my analysis will be through a different process of analysis than I used in my first two analyses.

This anaysis will use an alternative sequence to analyze a different set of three sentiment datasets within the "tidytext" package. 

The dictionaries are "bing", "nrc", (which I used previously) and "AFINN".

```{r include=FALSE}
# load libraries

library(cleanNLP)
library(tidytext)
library(tidyverse)
library(quanteda)
library(reticulate)
library(spacyr)
library(plyr); library(dplyr)
library(quanteda.textmodels)
library(quanteda.textplots)
library(quanteda.dictionaries)
library(quanteda.sentiment)
library(jsonlite)
library(caret)
library(magrittr)
library(stringr)
library(tidyr)
library(widyr)
library(ggplot2)
suppressWarnings(expr)
```

## Load Data

Loading the data from the expanded analysis:

```{r code_folding = TRUE}
#load data
main_headlines <- read.csv("afghanistan_headlines_main.csv")
main_headlines <- as.data.frame(main_headlines)
#turn into data frame
print_headlines <- read.csv("afghanistan_headlines_print.csv")
print_headlines <- as.data.frame(print_headlines)
```

## Bing Lexicon

The bing lexicon sorts words into positive or negative positions.

First I'll create tokens for the main and print headlines.

```{r code_folding = TRUE, message=FALSE}
#create tokens without stop words for main headlines
tkn_l_main <- apply(main_headlines, 1, function(x) { data.frame(text=x, stringsAsFactors = FALSE) %>% unnest_tokens(word, text)})
main_news_tokens <- lapply(tkn_l_main, function(x) {anti_join(x, stop_words)})
str(main_news_tokens, list.len = 5)
main_news_tokens[[1]]

#create tokens without stop words for print headlines
tkn_l_print <- apply(print_headlines, 1, function(x) { data.frame(text=x, stringsAsFactors = FALSE) %>% unnest_tokens(word, text)})
print_news_tokens <- lapply(tkn_l_print, function(x) {anti_join(x, stop_words)})
str(print_news_tokens, list.len = 5)
print_news_tokens[[1]]
```

### Create Function

I need to next create a function to assign sentiment labels.

```{r code_folding = TRUE}
compute_sentiment <- function(d) {
  if (nrow(d) == 0) {
    return(NA)
  }
  neg_score <- d %>% filter(sentiment=="negative") %>% nrow()
  pos_score <- d %>% filter(sentiment=="positive") %>% nrow()
  pos_score - neg_score
} 
```

### Apply Sentiments and Function

Then I can apply that sentiment function to the headline data sets

```{r code_folding = TRUE, message=FALSE}

sentiments_bing <- get_sentiments("bing")

#apply sentiment to main headlines
main_news_sentiment_bing <- sapply(main_news_tokens, function(x) { x %>% inner_join(sentiments_bing) %>% compute_sentiment()})
#apply sentiment to print headlines
print_news_sentiment_bing <- sapply(print_news_tokens, function(x) { x %>% inner_join(sentiments_bing) %>% compute_sentiment()})
```

### Summary

The summaries of each show the number of NA's are minimal.

```{r code_folding = TRUE, message=FALSE}
summary(main_news_sentiment_bing)
summary(print_news_sentiment_bing)
```

### Preview Results

Now I can look at the first 10 headlines and the corresponding bing analysis scores. I can see that the scores vary, even in the first 10 headlines.

```{r code_folding = TRUE, message=FALSE}
#head 10 main headlines with bing analysis scores
main_news_sentiment_bing_df <- data.frame(main_text=main_headlines$text, score = main_news_sentiment_bing)
head(main_news_sentiment_bing_df, 10)

#head 10 print headlines with bing analysis scores
print_news_sentiment_bing_df <- data.frame(print_text=print_headlines$text, score = print_news_sentiment_bing)
head(print_news_sentiment_bing_df, 10)
```

## NRC

As I saw in my first two analyses, the NRC lexicon uses 10 different sentiments, including negative and positive but with additional sentiments as well.

```{r code_folding = TRUE, message=FALSE}
sentiments_nrc <- get_sentiments("nrc")
(unique_sentiments_nrc <- unique(sentiments_nrc$sentiment))
```

### Create Function

Next again I will create a function to assign sentiment labels that apply 'positive' and 'negative' in a binary interpretation of each of the 8 other sentiments.

```{r code_folding = TRUE, message=FALSE}
compute_pos_neg_sentiments_nrc <- function(the_sentiments_nrc) {
  s <- unique(the_sentiments_nrc$sentiment)
  df_sentiments <- data.frame(sentiment = s, 
                              mapped_sentiment = c("positive", "negative", "negative", "negative",
                                                    "negative", "positive", "positive", "negative", 
                                                    "positive", "positive"))
  ss <- sentiments_nrc %>% inner_join(df_sentiments)
  the_sentiments_nrc$sentiment <- ss$mapped_sentiment
  the_sentiments_nrc
}

nrc_sentiments_pos_neg_scale <- compute_pos_neg_sentiments_nrc(sentiments_nrc)
```

### Apply Function

Then I can apply that sentiment function to the headline data sets

```{r code_folding = TRUE, message=FALSE}
#calculating NRC sentiment for main headlines
main_news_sentiment_nrc <- sapply(main_news_tokens, function(x) { x %>% inner_join(nrc_sentiments_pos_neg_scale) %>% compute_sentiment()})

#calculating NRC sentiment for print headlines
print_news_sentiment_nrc <- sapply(print_news_tokens, function(x) { x %>% inner_join(nrc_sentiments_pos_neg_scale) %>% compute_sentiment()})
```

### Summary

The summaries of each show the number of NA's are even more minimal.

```{r code_folding = TRUE, message=FALSE}
summary(main_news_sentiment_nrc)
summary(print_news_sentiment_nrc)
```

### Preview Results

Now I can look at the first 10 headlines and the corresponding NRC analysis scores. I can see that the scores vary as well, even in the first 10 headlines.

```{r code_folding = TRUE, message=FALSE}
#data frame of main NRC sentiment
main_news_sentiment_nrc_df <- data.frame(main_text=main_headlines$text, score = main_news_sentiment_nrc)
head(main_news_sentiment_nrc_df, 10)

#data frame of print NRC sentiment
print_news_sentiment_nrc_df <- data.frame(print_text=print_headlines$text, score = print_news_sentiment_nrc)
head(print_news_sentiment_nrc_df, 10)
```

### Visualization

```{r code_folding = TRUE, message=FALSE}
#transpose
td<-data.frame(t(d))
#The function rowSums computes column sums across rows for each level of a grouping variable.
td_new <- data.frame(rowSums(td[2:253]))
#Transformation and cleaning
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
#Plot One - count of words associated with each sentiment
quickplot(sentiment, data=td_new2, weight=count, geom="bar", fill=sentiment, ylab="count")+ggtitle("Survey sentiments")
You can see the bar plot in Figure 11.
```

## AFINN

The AFINN lexicon has valence ratings between -5 (negative) and +5 (positive).

```{r code_folding = TRUE, message=FALSE}
sentiments_afinn <- get_sentiments("afinn")

colnames(sentiments_afinn) <- c("word", "sentiment")
```

### Create Function

Again I'll create a function to assign sentiment labels.

```{r echo=TRUE, message=FALSE}
#applying AFINN sentiment to main headlines
main_news_sentiment_afinn_df <- lapply(main_news_tokens, function(x) { x %>% inner_join(sentiments_afinn)})
main_news_sentiment_afinn <- sapply(main_news_sentiment_afinn_df, function(x) { 
      ifelse(nrow(x) > 0, sum(x$sentiment), NA)
  })
#applying AFINN sentiment to print headlines
print_news_sentiment_afinn_df <- lapply(print_news_tokens, function(x) { x %>% inner_join(sentiments_afinn)})
print_news_sentiment_afinn <- sapply(print_news_sentiment_afinn_df, function(x) { 
      ifelse(nrow(x) > 0, sum(x$sentiment), NA)
  })
```

### Summary

The summaries of each show the number of NA's are similar to that in the bing lexicon. 

```{r code_folding = TRUE, message=FALSE}
summary(main_news_sentiment_afinn)
summary(print_news_sentiment_afinn)
```

### Preview Results

Now I can look at the first 10 headlines and the corresponding AFINN analysis scores. I can see that the scores vary a lot less than in the first two lexicons.

```{r code_folding = TRUE, message=FALSE}
#data frame of AFINN main headlines
main_news_sentiment_afinn_df <- data.frame(main_text=main_headlines$text, score = main_news_sentiment_afinn)
head(main_news_sentiment_afinn_df, 10)

#data frame of AFINN print headlines
print_news_sentiment_afinn_df <- data.frame(print_text=print_headlines$text, score = print_news_sentiment_afinn)
head(print_news_sentiment_afinn_df, 10)
```

## Congruence

Having obtained for each headline data set three potential results as sentiment evaluation, next I will calculate their congruence.

By congruence, I am looking at the fact that all three lexicons express a positive or negative result. In other words, the same score signal the same sentiment independently from the lexicon's respective scale of magnitude. If "NA" values are present, the congruence is computed until at least two non-"NA" values are available, otherwise the value is equal to "NA".

Then, I compute the final news sentiment as based upon the sum of each lexicon sentiment score.

### Create Function

```{r code_folding = TRUE, message=FALSE}
compute_congruence <- function(x,y,z) {
  v <- c(sign(x), sign(y), sign(z))
  # if only one lexicon reports the score, we cannot check for congruence
  if (sum(is.na(v)) >= 2) {
    return (NA)
  }
  # removing NA and zero value
  v <- na.omit(v)
  v_sum <- sum(v)
  abs(v_sum) == length(v)
}
```

```{r code_folding = TRUE, message=FALSE}
compute_final_sentiment <- function(x,y,z) {
  if (is.na(x) && is.na(y) && is.na(z)) {
    return (NA)
  }

  s <- sum(x, y, z, na.rm=TRUE)
  # positive sentiments have score strictly greater than zero
  # negative sentiments have score strictly less than zero
  # neutral sentiments have score equal to zero 
  ifelse(s > 0, "positive", ifelse(s < 0, "negative", "neutral"))
}
```

### Apply Function

Now I will put the sentiment results in new data frames and apply the analyses.

```{r code_folding = TRUE, message=FALSE}

main_sentiments_results <- data.frame(main_text = main_headlines$text, 
                                 bing_score = main_news_sentiment_bing, 
                                 nrc_score = main_news_sentiment_nrc, 
                                 afinn_score = main_news_sentiment_afinn,
                                 stringsAsFactors = FALSE)

print_sentiments_results <- data.frame(print_text = print_headlines$text, 
                                 bing_score = print_news_sentiment_bing, 
                                 nrc_score = print_news_sentiment_nrc, 
                                 afinn_score = print_news_sentiment_afinn,
                                 stringsAsFactors = FALSE)


main_sentiments_results <- main_sentiments_results %>% rowwise() %>% 
  mutate(final_sentiment = compute_final_sentiment(bing_score, nrc_score, afinn_score),
         congruence = compute_congruence(bing_score, nrc_score, afinn_score))

print_sentiments_results <- print_sentiments_results %>% rowwise() %>% 
  mutate(final_sentiment = compute_final_sentiment(bing_score, nrc_score, afinn_score),
         congruence = compute_congruence(bing_score, nrc_score, afinn_score))

head(main_sentiments_results, 10)
head(print_sentiments_results, 10)

```

### Evaluation

It seems like I need to do more work on the congruence function, as I have all "NA" results.

```{r code_folding = TRUE, message=FALSE}
#If it would be useful to replace the numeric score with same {negative, neutral, positive} scale.
replace_score_with_sentiment <- function(v_score) {
  v_score[v_score > 0] <- "positive"
  v_score[v_score < 0] <- "negative"
  v_score[v_score == 0] <- "neutral"
  v_score
} 
```

I'll combine all of the normalized and binary 'positive' and 'negative' sentiments from all three lexicons into one data frame for each headline set.

```{r code_folding=TRUE}
#apply scale to main results
main_sentiments_results$bing_score <- replace_score_with_sentiment(main_sentiments_results$bing_score)
main_sentiments_results$nrc_score <- replace_score_with_sentiment(main_sentiments_results$nrc_score)
main_sentiments_results$afinn_score <- replace_score_with_sentiment(main_sentiments_results$afinn_score)
main_sentiments_results[,2:5] <- lapply(main_sentiments_results[,2:5], as.factor)
head(main_sentiments_results, 40)

#apply scale to print results
print_sentiments_results$bing_score <- replace_score_with_sentiment(print_sentiments_results$bing_score)
print_sentiments_results$nrc_score <- replace_score_with_sentiment(print_sentiments_results$nrc_score)
print_sentiments_results$afinn_score <- replace_score_with_sentiment(print_sentiments_results$afinn_score)
print_sentiments_results[,2:5] <- lapply(print_sentiments_results[,2:5], as.factor)
head(print_sentiments_results, 40)


```

### Final Results

I'll take the overall sentiment score and join them in one data frame and visualize it. After taking the value 'positive' or 'negative' that is in the majority of the 3 evaluations, the dataset is overwhelmingly 'negative' (100%).

```{r code_folding = TRUE, message=FALSE}

final_total <- read.csv("all_sentiments_binary.csv")

head(final_total)
```

## Visualization

```{r code_folding = TRUE, message=FALSE}

#created matrix of tallies from this function for each test
#print_bing <- final_total %>%
        #group_by(print_bing) %>%
        #tally()
gg_data <- read.csv("gg_data2.csv")

theme_set(theme_classic())

# Histogram on a Categorical variable
ggplot(gg_data, aes(x=sentiment, fill = dictionary, stat_count(n))) +
  geom_col() +
  facet_wrap(~headlines)

df %>% tidyr::gather("id", "value", 1:4) %>% 
  ggplot(., aes(Xax, value))+
  geom_point()+
  geom_smooth(method = "lm", se=FALSE, color="black")+
  facet_wrap(~id)


```



# Other Types of Analysis

## Utilizing the cleanNLP package:

As usual, I am struggling to get this to work due to my inexperience with the python backend. What worked for me last time I ran this in a previous tutorial was no longer working, so I had to uninstall my miniconda installation and re-install it, but eventually it initialized so I could run the "cnlp_annotate" function.

```{r code_folding = TRUE, message=FALSE}

cnlp_init_udpipe()

#first the main headlines

main_tibble <- as_tibble(main_headlines) %>%
  select(c("doc_id", "text"))
main_tibble <- utf8::as_utf8(main_tibble$text)

annotated_main <- cnlp_annotate(main_tibble)

#then the print headlines

print_tibble <- as_tibble(print_headlines) %>%
  select(c("doc_id", "text"))
print_tibble <- utf8::as_utf8(print_tibble$text)

annotated_print <- cnlp_annotate(print_tibble)

```

## Using spaCyr

### For Main Headlines

```{r code_folding = TRUE, message=FALSE}

parsed_main <- spacy_parse(main_headlines,
                           lemma = TRUE,
                           entity = TRUE,
                           nounphrase = TRUE,
                           sentiment = TRUE,
                           additional_attributes = c("is_punct",
                                                     "is_stop",
                                                     "is_currency",
                                                     "is_digit",
                                                     "is_quote")) %>%
  as_tibble %>%
  select(-sentence_id)

head(parsed_main)
summary(parsed_main)
```

### For Print Headlines

```{r code_folding = TRUE, message=FALSE}

parsed_print <- spacy_parse(print_headlines,
                           lemma = TRUE,
                           entity = TRUE,
                           nounphrase = TRUE,
                           additional_attributes = c("is_punct",
                                                     "is_stop",
                                                     "is_currency",
                                                     "is_digit",
                                                     "is_quote",
                                                     "sentiment")) %>%
  as_tibble %>%
  select(-sentence_id)

head(parsed_print)
summary(parsed_print)
```

# Citations

Citations:

* This research makes use of the [NRC Word-Emotion Association Lexicon](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm), created by Saif Mohammad and Peter Turney at the National Research Council Canada. 

* This research makes use of the [Bing Lexicon](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html). This dataset was first published in Minqing Hu and Bing Liu, ``Mining and summarizing customer reviews.'', Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD-2004), 2004.

* This research makes use of the [AFINN Lexicon](http://www2.compute.dtu.dk/pubdb/pubs/6010-full.html), Nielsen, F. Ã…. (2011). A new ANEW: Evaluation of a word list for sentiment analysis in microblogs. arXiv preprint arXiv:1103.2903.

