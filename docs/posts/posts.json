[
  {
    "path": "posts/headline-analysis/",
    "title": "Analysis of Main vs. Print Headlines",
    "description": "Text as Data Project Headline Comparison Research",
    "author": [
      {
        "name": "Kristina Becvar",
        "url": "https://kbec19.github.io/NYT-Analysis/"
      }
    ],
    "date": "2022-04-17",
    "categories": [
      "text as data",
      "NYT text analysis project"
    ],
    "contents": "\r\n\r\nContents\r\nComparing\r\nMain vs. Print Headlines in the New York Times\r\nResearch Background\r\nMaking\r\nChoices on Inclusion of Observations\r\nGathering Data\r\nPrevious Process\r\nLoad Data\r\nLoad Data\r\nCreate Corpus\r\nAssign Type to Docvars\r\nTokenization\r\nDocument Feature Matrix\r\n\r\nDictionary Analysis\r\nliwcalike()\r\nNRC\r\nLSD 2015\r\nGeneral Inquirer\r\nAnnotation\r\n\r\n\r\n\r\nComparing\r\nMain vs. Print Headlines in the New York Times\r\nResearch Background\r\nDuring the Fall 2021 semester, my research group hand coded PDF\r\ncopies of articles resulting from a simple search on the websites of the\r\nNew York Times and Wall Street Journal from Feburary 29, 2020 through\r\nSeptember 30, 2021 using the term “Afghanistan withdrawal”. One thing I\r\nnoticed was that when loading the PDF articles into NVivo for coding was\r\nthat it was difficult to match the New York Times articles to the\r\ncitation information in Zotero for many of the articles because the\r\narticle titles did not match. I realized that in the process of saving\r\nthe articles in Zotero, they were saved with the title viewable on the\r\nweb version of the article; however, once the article had been preserved\r\nby using the site’s “Print to PDF” function, the article title that it\r\nused as a default file name was different than the web version.\r\nThis semester, I began this project to be one expanding on last\r\nsemester’s research and looking to expand a machine analysis of articles\r\npulling articles beginning January 2020 through December 2021. For my\r\ninitial text collection, I collected articles using the New York Times\r\nAPI for the search query “Afghanistan”, and hoped to be able to analyze\r\nthe full text of a larger range of articles.\r\nHowever, I found that I am limited in that the article search API for\r\nthe New York Times does not pull the entire article; rather, I was able\r\nto pull the abstract/summary, lead paragraph, and snippet for each\r\narticle as well as the keywords, authors, sections, and url. In\r\naddition, I was able to get the article titles for both the print and\r\nonline versions of the article.\r\nThe API’s lack of full article text was not optimal for my purposes;\r\nto examine sentiment and co-occurence of various sources. Sources are\r\nnot necessarily detailed in the lead paragraph or abstract of an\r\narticle, so I moved to a different research path.\r\nRemembering the differences in headlines from our manual coding\r\nresearch and noting that the API provides both headlines in the article\r\nsearch API, I turned to analyzing the differences in the main vs. print\r\nheadlines for articles from the same research period as our first\r\nexamination. This way, I can potentially use a sample of the full\r\narticles collected in our previous research and take the additional step\r\nof analyzing the sentiment of full articles and how they may or may not\r\nrelate to the differing headlines.\r\nMaking Choices on\r\nInclusion of Observations\r\nIn my initial look at the headline data, it was clear that not all of\r\nthe articles had different headlines; some are the same entries, and\r\nsome have “N/A” in the “print” version only, indicating they were\r\nonline-only stories. Although I initially felt inclined to leave the\r\n“N/A” observations in the analysis, I removed those observations as they\r\nwould not be relevant to my new research questions comparing the framing\r\nfor different audiences.\r\nI also removed whole sections where the API returned an observation\r\nas there was apparently use of the term “Afghanistan withdrawal”\r\nsomewhere in the article/entry, but the type of entry was clearly not\r\nbeing represented in the headline. For example, “Corrections” entries\r\nhave headlines consisting only of the term “Corrections” and the\r\ncorresponding date. Similar choices were made on the “Arts”, Books”, and\r\n“Podcasts” sections when entries are primarily the names of the things\r\nbeing reviewed that may have a reference to the Afghanistan withdrawal\r\nsomewhere in the text, but it is not relevant specifically to the\r\nwithdrawal time period being analyzed.\r\nWith few exceptions, this left the entirety of the “U.S.” and “World”\r\nnews sections, even if the content related to Afghanistan is not readily\r\nobservable. The count (~650) matched the number of articles pulled for\r\nthe hand coding research as well.\r\nGathering Data\r\nPrevious Process\r\nTo pull the data, I had to reduce the queries into more workable\r\ngroups that would not time out, given the NYT API limits. I was able to\r\npull the ~700 articles by chunk, then assemble them into a dataframe\r\nafter cleaning. I will not run the code in this post, as it was already\r\nrun and is an exhaustive process.\r\n\r\n\r\n\r\nAfter compiling the data, I re-formatted the date column and saving\r\nthe formatted tibble for offline access.\r\n\r\n\r\n\r\nLoad Data\r\nNow to the active review of the data. Loading the data from my\r\ncollection phase:\r\nLoad Data\r\n\r\n  article_id      date\r\n1          1 2/29/2020\r\n2          2 2/29/2020\r\n3          3  3/1/2020\r\n4          4  3/2/2020\r\n5          5  3/2/2020\r\n6          6  3/3/2020\r\n                                                                 headline_main\r\n1                              4 Takeaways From the U.S. Deal With the Taliban\r\n2    Taliban and U.S. Strike Deal to Withdraw American Troops From Afghanistan\r\n3           Afghanistan War Enters New Stage as U.S. Military Prepares to Exit\r\n4                 At Center of Taliban Deal, a U.S. Envoy Who Made It Personal\r\n5 U.S. Announces Troop Withdrawal in Afghanistan as Respite From Violence Ends\r\n6                                           Trump Speaks With a Taliban Leader\r\n  article_id      date\r\n1          1 2/29/2020\r\n2          2 2/29/2020\r\n3          3  3/1/2020\r\n4          4  3/2/2020\r\n5          5  3/2/2020\r\n6          6  3/3/2020\r\n                                                        headline_print\r\n1                                 Table Is Set For a Pullout And Talks\r\n2                              U.S. and Taliban Sign Withdrawal Accord\r\n3                                      A Mission Shift for Afghanistan\r\n4 At the Center of the Taliban Deal, a U.S. Envoy Who Made It Personal\r\n5                           U.S. Troop Reduction Begins in Afghanistan\r\n6               Pursuing Exit, Trump Talks  To a Leader Of the Taliban\r\n\r\nCreate Corpus\r\n\r\n\r\nmain_corpus <- corpus(main_headlines, docid_field = \"article_id\", text_field = \"headline_main\")\r\nprint_corpus <- corpus(print_headlines, docid_field = \"article_id\", text_field = \"headline_print\")\r\n\r\n\r\n\r\nAssign Type to Docvars\r\n\r\n\r\nmain_corpus$type <- \"Main Headline\"\r\nprint_corpus$type <- \"Print Headline\"\r\ndocvars(main_corpus, field = \"type\") <- main_corpus$type\r\ndocvars(print_corpus, field = \"type\") <- print_corpus$type\r\n\r\n\r\n\r\nTokenization\r\nAfter many process posts, I finally realized how to remove the “�”\r\nsymbol that has plagued me since starting working with this API by using\r\n“remove_symbols=TRUE” in addition to removing the punctuation when\r\ntokenizing. I also want to remove stopwords.\r\nMain Headlines\r\n\r\n[1] 346\r\nTokens consisting of 346 documents and 2 docvars.\r\n1 :\r\n[1] \"4\"         \"Takeaways\" \"U.S\"       \"Deal\"      \"Taliban\"  \r\n\r\n2 :\r\n[1] \"Taliban\"     \"U.S\"         \"Strike\"      \"Deal\"       \r\n[5] \"Withdraw\"    \"American\"    \"Troops\"      \"Afghanistan\"\r\n\r\n3 :\r\n[1] \"Afghanistan\" \"War\"         \"Enters\"      \"New\"        \r\n[5] \"Stage\"       \"U.S\"         \"Military\"    \"Prepares\"   \r\n[9] \"Exit\"       \r\n\r\n4 :\r\n[1] \"Center\"   \"Taliban\"  \"Deal\"     \"U.S\"      \"Envoy\"    \"Made\"    \r\n[7] \"Personal\"\r\n\r\n5 :\r\n[1] \"U.S\"         \"Announces\"   \"Troop\"       \"Withdrawal\" \r\n[5] \"Afghanistan\" \"Respite\"     \"Violence\"    \"Ends\"       \r\n\r\n6 :\r\n[1] \"Trump\"   \"Speaks\"  \"Taliban\" \"Leader\" \r\n\r\n[ reached max_ndoc ... 340 more documents ]\r\n\r\nPrint Headlines\r\n\r\n[1] 346\r\nTokens consisting of 346 documents and 2 docvars.\r\n1 :\r\n[1] \"Table\"   \"Set\"     \"Pullout\" \"Talks\"  \r\n\r\n2 :\r\n[1] \"U.S\"        \"Taliban\"    \"Sign\"       \"Withdrawal\" \"Accord\"    \r\n\r\n3 :\r\n[1] \"Mission\"     \"Shift\"       \"Afghanistan\"\r\n\r\n4 :\r\n[1] \"Center\"   \"Taliban\"  \"Deal\"     \"U.S\"      \"Envoy\"    \"Made\"    \r\n[7] \"Personal\"\r\n\r\n5 :\r\n[1] \"U.S\"         \"Troop\"       \"Reduction\"   \"Begins\"     \r\n[5] \"Afghanistan\"\r\n\r\n6 :\r\n[1] \"Pursuing\" \"Exit\"     \"Trump\"    \"Talks\"    \"Leader\"   \"Taliban\" \r\n\r\n[ reached max_ndoc ... 340 more documents ]\r\n\r\nDocument Feature Matrix\r\n\r\n\r\n\r\n\r\n\r\n#create a word frequency variable and the rankings\r\nmain_counts <- as.data.frame(sort(colSums(main_dfm),dec=T))\r\ncolnames(main_counts) <- c(\"Frequency\")\r\nmain_counts$Rank <- c(1:ncol(main_dfm))\r\nhead(main_counts)\r\n\r\n\r\n            Frequency Rank\r\nu.s               100    1\r\nafghanistan        87    2\r\nafghan             85    3\r\ntaliban            65    4\r\nbiden              53    5\r\nwar                30    6\r\n\r\nprint_counts <- as.data.frame(sort(colSums(print_dfm),dec=T))\r\ncolnames(print_counts) <- c(\"Frequency\")\r\nprint_counts$Rank <- c(1:ncol(print_dfm))\r\nhead(print_counts)\r\n\r\n\r\n            Frequency Rank\r\nu.s               100    1\r\ntaliban            66    2\r\nafghan             64    3\r\nafghanistan        56    4\r\nbiden              41    5\r\nexit               27    6\r\n\r\nNow I can take a look at this network of feature co-occurrences for\r\nthe main headlines:\r\n\r\n[1] 1232 1232\r\n[1] 20 20\r\n\r\n\r\nand for the print headlines:\r\n\r\n[1] 1178 1178\r\n[1] 20 20\r\n\r\n\r\nThis brings me to where I had previously stopped in my comparison and\r\nanalysis, and now that I’m able to produce a cleaner result, I’ll move\r\non to further analysis using the quanteda dictionary.\r\nDictionary Analysis\r\nliwcalike()\r\n\r\n [1] \"docname\"      \"Segment\"      \"WPS\"          \"WC\"          \r\n [5] \"Sixltr\"       \"Dic\"          \"anger\"        \"anticipation\"\r\n [9] \"disgust\"      \"fear\"         \"joy\"          \"negative\"    \r\n[13] \"positive\"     \"sadness\"      \"surprise\"     \"trust\"       \r\n[17] \"AllPunc\"      \"Period\"       \"Comma\"        \"Colon\"       \r\n[21] \"SemiC\"        \"QMark\"        \"Exclam\"       \"Dash\"        \r\n[25] \"Quote\"        \"Apostro\"      \"Parenth\"      \"OtherP\"      \r\n\r\nNRC\r\n\r\n\r\n# convert tokens from each headline data set to DFM using the dictionary \"NRC\"\r\nmain_nrc <- dfm(main_tokens) %>%\r\n  dfm_lookup(data_dictionary_NRC)\r\nprint_nrc <- dfm(print_tokens) %>%\r\n  dfm_lookup(data_dictionary_NRC)\r\n\r\ndim(main_nrc)\r\n\r\n\r\n[1] 346  10\r\n\r\nmain_nrc\r\n\r\n\r\nDocument-feature matrix of: 346 documents, 10 features (69.36% sparse) and 2 docvars.\r\n    features\r\ndocs anger anticipation disgust fear joy negative positive sadness\r\n   1     0            1       0    0   1        0        1       0\r\n   2     1            1       0    0   1        2        1       1\r\n   3     0            0       0    2   0        1        0       0\r\n   4     0            1       0    0   1        0        2       0\r\n   5     1            0       0    1   1        1        1       1\r\n   6     0            0       0    0   0        0        1       0\r\n    features\r\ndocs surprise trust\r\n   1        1     1\r\n   2        1     1\r\n   3        0     0\r\n   4        1     3\r\n   5        0     1\r\n   6        1     1\r\n[ reached max_ndoc ... 340 more documents ]\r\n\r\ndim(print_nrc)\r\n\r\n\r\n[1] 346  10\r\n\r\nprint_nrc\r\n\r\n\r\nDocument-feature matrix of: 346 documents, 10 features (71.47% sparse) and 2 docvars.\r\n    features\r\ndocs anger anticipation disgust fear joy negative positive sadness\r\n   1     0            0       0    0   0        0        0       0\r\n   2     0            0       0    0   0        0        1       0\r\n   3     0            0       0    0   0        0        0       0\r\n   4     0            1       0    0   1        0        2       0\r\n   5     0            0       0    0   0        0        0       0\r\n   6     0            0       0    0   0        0        1       0\r\n    features\r\ndocs surprise trust\r\n   1        0     0\r\n   2        0     1\r\n   3        0     0\r\n   4        1     3\r\n   5        0     0\r\n   6        1     1\r\n[ reached max_ndoc ... 340 more documents ]\r\n\r\nAnd use the information in a data frame to plot the output:\r\n\r\n\r\n#for the main headlines\r\ndf_main_nrc <- convert(main_nrc, to = \"data.frame\")\r\ndf_main_nrc$polarity <- (df_main_nrc$positive - df_main_nrc$negative)/(df_main_nrc$positive + df_main_nrc$negative)\r\ndf_main_nrc$polarity[which((df_main_nrc$positive + df_main_nrc$negative) == 0)] <- 0\r\n\r\nggplot(df_main_nrc) + \r\n  geom_histogram(aes(x=polarity)) + \r\n  theme_bw()\r\n\r\n\r\n\r\n#and the print headlines\r\ndf_print_nrc <- convert(print_nrc, to = \"data.frame\")\r\ndf_print_nrc$polarity <- (df_print_nrc$positive - df_print_nrc$negative)/(df_print_nrc$positive + df_print_nrc$negative)\r\ndf_print_nrc$polarity[which((df_print_nrc$positive + df_print_nrc$negative) == 0)] <- 0\r\n\r\nggplot(df_print_nrc) + \r\n  geom_histogram(aes(x=polarity)) + \r\n  theme_bw()\r\n\r\n\r\n\r\n\r\nLooking at the headlines that are indicated as “1”, or positive in\r\nsentiment, it’s clear that this dictionary is not capturing the\r\nsentiment accurately.\r\n\r\n\r\nhead(main_corpus[which(df_main_nrc$polarity == 1)])\r\n\r\n\r\nCorpus consisting of 6 documents and 2 docvars.\r\n1 :\r\n\"4 Takeaways From the U.S. Deal With the Taliban\"\r\n\r\n4 :\r\n\"At Center of Taliban Deal, a U.S. Envoy Who Made It Personal\"\r\n\r\n6 :\r\n\"Trump Speaks With a Taliban Leader\"\r\n\r\n8 :\r\n\"After Tours in Afghanistan, U.S. Veterans Weigh Peace With t...\"\r\n\r\n9 :\r\n\"Javier Pérez de Cuéllar Dies at 100; U.N. Chief Brokered Pea...\"\r\n\r\n10 :\r\n\"From the Afghan Peace Deal, a Weak and Pliable Neighbor for ...\"\r\n\r\nhead(print_corpus[which(df_print_nrc$polarity == 1)])\r\n\r\n\r\nCorpus consisting of 6 documents and 2 docvars.\r\n2 :\r\n\"U.S. and Taliban Sign Withdrawal Accord\"\r\n\r\n4 :\r\n\"At the Center of the Taliban Deal, a U.S. Envoy Who Made It ...\"\r\n\r\n6 :\r\n\"Pursuing Exit, Trump Talks  To a Leader Of the Taliban\"\r\n\r\n7 :\r\n\"Attacks on Afghans by Taliban Rise After Signing of Peace De...\"\r\n\r\n8 :\r\n\"After Afghanistan Tours,  U.S. Veterans Appraise  Peace Deal...\"\r\n\r\n9 :\r\n\"Javier Pérez de Cuéllar, U.N. Chief  Behind Vital Peace Pact...\"\r\n\r\nLSD 2015\r\nI am going to want to look at multiple dictionaries to see if one can\r\nbest apply to this data. First, the LSD 2015 dictionary:\r\n\r\n\r\n# convert main corpus to DFM using the LSD2015 dictionary\r\nmain_lsd2015 <- dfm(tokens(main_corpus, remove_punct = TRUE),\r\n                              tolower = TRUE) %>%\r\n                          dfm_lookup(data_dictionary_LSD2015)\r\n# create main polarity measure for LSD2015\r\nmain_lsd2015 <- convert(main_lsd2015, to = \"data.frame\")\r\nmain_lsd2015$polarity <- (main_lsd2015$positive - main_lsd2015$negative)/(main_lsd2015$positive + main_lsd2015$negative)\r\nmain_lsd2015$polarity[which((main_lsd2015$positive + main_lsd2015$negative) == 0)] <- 0\r\n# convert print corpus to DFM using the LSD2015 dictionary\r\nprint_lsd2015 <- dfm(tokens(print_corpus, remove_punct = TRUE),\r\n                              tolower = TRUE) %>%\r\n                          dfm_lookup(data_dictionary_LSD2015)\r\n# create print polarity measure for LSD2015\r\nprint_lsd2015 <- convert(print_lsd2015, to = \"data.frame\")\r\nprint_lsd2015$polarity <- (print_lsd2015$positive - print_lsd2015$negative)/(print_lsd2015$positive + print_lsd2015$negative)\r\nprint_lsd2015$polarity[which((print_lsd2015$positive + print_lsd2015$negative) == 0)] <- 0\r\n\r\n\r\n\r\nGeneral Inquirer\r\nand the General Inquirer dictionary:\r\n\r\n\r\n# convert main corpus to DFM using the General Inquirer dictionary\r\nmain_geninq <- dfm(tokens(main_corpus, remove_punct = TRUE),\r\n                             tolower = TRUE) %>%\r\n                    dfm_lookup(data_dictionary_geninqposneg)\r\n# create main polarity measure for GenInq\r\nmain_geninq <- convert(main_geninq, to = \"data.frame\")\r\nmain_geninq$polarity <- (main_geninq$positive - main_geninq$negative)/(main_geninq$positive + main_geninq$negative)\r\nmain_geninq$polarity[which((main_geninq$positive + main_geninq$negative) == 0)] <- 0\r\n# convert print corpus to DFM using the General Inquirer dictionary\r\nprint_geninq <- dfm(tokens(print_corpus, remove_punct = TRUE),\r\n                             tolower = TRUE) %>%\r\n                    dfm_lookup(data_dictionary_geninqposneg)\r\n# create print polarity measure for GenInq\r\nprint_geninq <- convert(print_geninq, to = \"data.frame\")\r\nprint_geninq$polarity <- (print_geninq$positive - print_geninq$negative)/(print_geninq$positive + print_geninq $negative)\r\nprint_geninq$polarity[which((print_geninq$positive + print_geninq$negative) == 0)] <- 0\r\n\r\n\r\n\r\nNow I’m going to be able to compare the different dictionary scores\r\nin one data frame for each type of headline.\r\n\r\n  nrc_doc_id nrc_anger nrc_anticipation nrc_disgust nrc_fear nrc_joy\r\n1          1         0                1           0        0       1\r\n2         10         0                3           0        0       2\r\n3        100         0                0           0        0       0\r\n4        101         0                2           0        0       1\r\n5        102         1                0           0        2       0\r\n6        103         1                1           0        1       0\r\n  nrc_negative nrc_positive nrc_sadness nrc_surprise nrc_trust\r\n1            0            1           0            1         1\r\n2            0            3           0            1         3\r\n3            1            0           1            0         0\r\n4            2            1           0            0         2\r\n5            2            0           2            1         0\r\n6            0            2           0            0         1\r\n  nrc_polarity lsd2015_negative lsd2015_positive lsd2015_neg_positive\r\n1    1.0000000                0                0                    0\r\n2    1.0000000                1                1                    0\r\n3   -1.0000000                1                0                    0\r\n4   -0.3333333                1                0                    0\r\n5   -1.0000000                2                0                    0\r\n6    1.0000000                0                0                    0\r\n  lsd2015_neg_negative lsd2015_polarity geninq_positive\r\n1                    0                0               1\r\n2                    0                0               2\r\n3                    0               -1               0\r\n4                    0               -1               0\r\n5                    0               -1               1\r\n6                    0                0               1\r\n  geninq_negative geninq_polarity\r\n1               1       0.0000000\r\n2               1       0.3333333\r\n3               0       0.0000000\r\n4               2      -1.0000000\r\n5               1       0.0000000\r\n6               1       0.0000000\r\n  nrc_doc_id nrc_anger nrc_anticipation nrc_disgust nrc_fear nrc_joy\r\n1          1         0                0           0        0       0\r\n2         10         0                2           0        0       1\r\n3        100         0                0           0        0       0\r\n4        101         0                2           0        0       1\r\n5        102         1                0           0        4       0\r\n6        103         1                1           0        1       0\r\n  nrc_negative nrc_positive nrc_sadness nrc_surprise nrc_trust\r\n1            0            0           0            0         0\r\n2            0            2           0            1         2\r\n3            1            0           1            0         0\r\n4            2            1           0            0         2\r\n5            3            0           3            1         0\r\n6            0            1           0            0         0\r\n  nrc_polarity lsd2015_negative lsd2015_positive lsd2015_neg_positive\r\n1    0.0000000                0                0                    0\r\n2    1.0000000                1                0                    0\r\n3   -1.0000000                1                0                    0\r\n4   -0.3333333                1                0                    0\r\n5   -1.0000000                2                0                    0\r\n6    1.0000000                0                0                    0\r\n  lsd2015_neg_negative lsd2015_polarity geninq_positive\r\n1                    0                0               0\r\n2                    0               -1               2\r\n3                    0               -1               0\r\n4                    0               -1               0\r\n5                    0               -1               1\r\n6                    0                0               1\r\n  geninq_negative geninq_polarity\r\n1               0       0.0000000\r\n2               1       0.3333333\r\n3               1      -1.0000000\r\n4               2      -1.0000000\r\n5               0       1.0000000\r\n6               0       1.0000000\r\n\r\nNow that we have them all in a single data frame, it’s\r\nstraightforward to figure out a bit about how well our different\r\nmeasures of polarity agree across the different approaches by looking at\r\ntheir correlation using the “cor()” function.\r\n\r\n\r\ncor(main_sent$nrc_polarity, main_sent$lsd2015_polarity)\r\n\r\n\r\n[1] 0.4968335\r\n\r\ncor(main_sent$nrc_polarity, main_sent$geninq_polarity)\r\n\r\n\r\n[1] 0.4813359\r\n\r\ncor(main_sent$lsd2015_polarity, main_sent$geninq_polarity)\r\n\r\n\r\n[1] 0.5327856\r\n\r\n\r\n\r\ncor(print_sent$nrc_polarity, print_sent$lsd2015_polarity)\r\n\r\n\r\n[1] 0.4197161\r\n\r\ncor(print_sent$nrc_polarity, print_sent$geninq_polarity)\r\n\r\n\r\n[1] 0.4917256\r\n\r\ncor(print_sent$lsd2015_polarity, print_sent$geninq_polarity)\r\n\r\n\r\n[1] 0.4921922\r\n\r\nAnnotation\r\n\r\n\r\nlibrary(cleanNLP)\r\ncnlp_init_udpipe()\r\n\r\n\r\n\r\n\r\n\r\nlibrary(tidyr)\r\n#amain <- as_tibble(headlines_main)\r\n#annotated_main <- cnlp_annotate(main_corpus)\r\n#annotated_main\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/headline-analysis/unnamed-chunk-12-1.png",
    "last_modified": "2022-04-23T00:12:27-05:00",
    "input_file": {}
  },
  {
    "path": "posts/pdf-analysis/",
    "title": "Analysis of PDF Articles",
    "description": "Text as Data Project-Article Sentiment Research",
    "author": [
      {
        "name": "Kristina Becvar",
        "url": "https://kbec19.github.io/NYT-Analysis/"
      }
    ],
    "date": "2022-04-17",
    "categories": [
      "text as data",
      "NYT text analysis project"
    ],
    "contents": "\r\n\r\nContents\r\nGetting Started\r\nPulling in the PDF docs\r\nExtracting PDF Files\r\nbeing examined\r\nInspect the first\r\narticle\r\nInspecting Individual\r\nArticles\r\nUnlist\r\nCreate Term Document\r\nMatrix\r\nInspect TDM\r\nFrequent Terms\r\nReturn Results in a Data\r\nFrame\r\nGenerate\r\nDocument-Feature Matrix\r\nTerms & Frequencies\r\nPreprocessing Choices\r\n\r\nTokenization\r\n\r\n\r\nGetting Started\r\nPulling in the PDF docs\r\nI have the PDF files in my working directory. Using the\r\n“list.files()” function from the “pdftools” package, I can create a\r\nvector of PDF file names, specifying only files that end in “.pdf”.\r\n\r\n\r\nShow code\r\n\r\n#load libraries\r\nlibrary(pdftools)\r\nlibrary(readtext)\r\nlibrary(readr)\r\nlibrary(tm)\r\nlibrary(tidytext)\r\nlibrary(stringr)\r\nlibrary(MASS)\r\nlibrary(tidyverse)\r\nlibrary(plyr); library(dplyr)\r\nlibrary(quanteda)\r\nlibrary(purrr)\r\nlibrary(here)\r\n\r\n\r\n\r\nExtracting PDF Files being\r\nexamined\r\n\r\n\r\n#create file names\r\nfiles <- list.files(pattern = \"pdf$\")\r\n\r\n#extract the pdf file data\r\nnyt_articles <- lapply(files, pdf_text)\r\n\r\n#apply length functions\r\nlapply(nyt_articles, length)\r\n\r\n\r\n[[1]]\r\n[1] 4\r\n\r\n[[2]]\r\n[1] 2\r\n\r\n[[3]]\r\n[1] 3\r\n\r\n[[4]]\r\n[1] 4\r\n\r\n[[5]]\r\n[1] 10\r\n\r\n[[6]]\r\n[1] 6\r\n\r\n[[7]]\r\n[1] 2\r\n\r\n[[8]]\r\n[1] 5\r\n\r\n[[9]]\r\n[1] 5\r\n\r\n[[10]]\r\n[1] 2\r\n\r\n#view the structure of the list\r\nstr(nyt_articles)\r\n\r\n\r\nList of 10\r\n $ : chr [1:4] \"                                 https://www.nytimes.com/2021/04/13/us/politics/samantha-power-biden.html\\n\\n\\n\"| __truncated__ \"                                Secretary of State Antony J. Blinken at the opening session of talks with China\"| __truncated__ \"The mostly benign prodding by Democrats and Republicans during the hearing signaled how countering China has be\"| __truncated__ \"“There is so much that can be done between bombing and nothing,” Mr. Prendergast said, paraphrasing Luis Moreno\"| __truncated__\r\n $ : chr [1:2] \"                            https://www.nytimes.com/2021/04/29/world/asia/central-asia-border-\\n               \"| __truncated__ \"In announcing the cease-fire, the Kyrgyz Ministry of Interior said that it “does not have\\ndesigns on foreign t\"| __truncated__\r\n $ : chr [1:3] \"                                https://www.nytimes.com/2021/08/05/us/politics/taliban-afghanistan-peace-deal.h\"| __truncated__ \"The statement came as Taliban representatives met with Afghan government officials, including Mr. Abdullah, for\"| __truncated__ \"“The Taliban is not interested in negotiating seriously right now because of what’s happening on the battlefiel\"| __truncated__\r\n $ : chr [1:4] \"                                https://www.nytimes.com/2021/08/08/us/politics/taliban-afghanistan-united-state\"| __truncated__ \"Over the past week, Taliban fighters have moved swiftly to retake cities around Afghanistan, assassinated gover\"| __truncated__ \"                                 Ms. Psaki speaking to reporters at the White House, on Friday. Tom Brenner for\"| __truncated__ \"Mr. Biden, declaring that the United States had long ago accomplished its mission of denying terrorists a haven\"| __truncated__\r\n $ : chr [1:10] \"                                https://www.nytimes.com/2021/08/30/world/asia/us-withdrawal-afghanistan-kabul.h\"| __truncated__ \"Old Soviet tanks litter the grounds of Bala Hissar, outside Kunduz. Jim Huylebroek for The New York Times\\n\" \"  Khalil Haqqani, a Taliban leader, appeared at Friday prayers in Kabul this month with an American-made M-4 ri\"| __truncated__ \"The Taliban’s leverage, earned after years of fighting the world’s most advanced military, multiplied as they c\"| __truncated__ ...\r\n $ : chr [1:6] \"                                 https://www.nytimes.com/2021/09/01/world/asia/afghanistan-taliban-government-l\"| __truncated__ \"  Internally displaced Afghans fleeing the fighting in the north still live at a camp in the Sarawi Shomali par\"| __truncated__ \"  A vendor selling Taliban flags in Kabul on Friday near posters of the senior Taliban officials Amir Khan Mutt\"| __truncated__ \"The Taliban are also fighting stubborn opposition forces led by National Resistance Front leaders in Panjshir P\"| __truncated__ ...\r\n $ : chr [1:2] \"                               https://www.nytimes.com/2021/09/02/us/politics/congress-pentagon-budget-biden.ht\"| __truncated__ \"The lopsided vote underscored another reality: Even as the hard-charging liberal bloc of lawmakers pledging to \"| __truncated__\r\n $ : chr [1:5] \"                                 https://www.nytimes.com/2021/09/07/us/politics/afghan-war-iraq-veterans.html\\n\"| __truncated__ \"                                Jen Burch said the doctors who examined her in 2014 found ground glass nodules \"| __truncated__ \"                                 Melissa Gauntner has dealt with dual traumas and has at times been gripped wit\"| __truncated__ \"In military families, scholars find what they call secondary traumatic distress, symptoms of anxiety stemming f\"| __truncated__ ...\r\n $ : chr [1:5] \"                                 https://www.nytimes.com/2020/10/05/world/asia/afghan-peace-talks-children.html\"| __truncated__ \"                                   Fatima Gailani, whose father was one of the leaders of the mujahedeen resist\"| __truncated__ \"                                Anas Haqqani, the youngest son of the insurgent chief Jalaluddin Haqqani, is pa\"| __truncated__ \"                                 Jalaluddin Haqqani in an undated photo from a video released by the Taliban on\"| __truncated__ ...\r\n $ : chr [1:2] \"                                https://www.nytimes.com/2020/03/04/world/asia/afghanistan-taliban-violence.html\"| __truncated__ \"     Understand the Taliban Takeover in Afghanistan\\n\\n     Who are the Taliban? The Taliban arose in 1994 amid\"| __truncated__\r\n\r\nInspect the first article\r\n\r\n\r\nhead(nyt_articles[1])\r\n\r\n\r\n[[1]]\r\n[1] \"                                 https://www.nytimes.com/2021/04/13/us/politics/samantha-power-biden.html\\n\\n\\n\\nAfter Backing Military Force in Past, U.S.A.I.D. Nominee Focuses on Deploying Soft\\nPower\\nIf confirmed to oversee the U.S. Agency for International Development, Samantha Power will confront adversaries by bolstering\\ndemocracy and human rights. China is an early focus.\\n\\n\\n          By Lara Jakes\\n\\nPublished April 13, 2021   Updated April 14, 2021\\n\\n\\nWASHINGTON — Near the end of the 2014 documentary “Watchers of the Sky,” which chronicles the origins of the legal definition\\nof genocide, Samantha Power grows emotional. At the time, Ms. Power was President Barack Obama’s ambassador to the United\\nNations, and, she said, had “great visibility into a lot of the pain” in the world.\\n\\nFrom that perch, preventing mass atrocities abroad required “thinking through what we can do about it, to exhaust the tools at your\\ndisposal,” Ms. Power said in the film. “And I always think about the privilege of, you know, of getting to try — just to try.”\\n\\nFew doubt Ms. Power’s zeal — given her career as a war correspondent, human rights activist, academic expert and foreign policy\\nadviser — even if it has meant advocating military force to stop widespread killings.\\n\\nNow, as President Biden’s nominee to lead the United States Agency for International Development, she is preparing to rejoin the\\ngovernment as an administrator of soft power, and resist using weapons as a means of deterrence and punishment that she has\\npushed for in the past.\\n\\nA Senate committee is expected to vote Thursday on her nomination to lead one of the world’s largest distributors of humanitarian\\naid.\\n\\nIf she is confirmed, Mr. Biden will also seat her on the National Security Council, where during the Obama administration she\\npressed for military intervention to protect civilians from state-sponsored attacks in Libya in 2011 and Syria in 2013. (However, she\\nalso opposed the 2003 invasion of Iraq.)\\n\\nThat she will be back at the table at the council — and again almost certain to be debating whether to entangle American forces in\\nenduring conflicts — has concerned some officials, analysts and think tank experts who demand military restraint from the Biden\\nadministration. Mr. Biden appears to be leaning that way: He has embraced economic sanctions as a tool of hard power and is\\nexpected to announce a full withdrawal of American troops from Afghanistan by Sept. 11, ending the United States’ longest war.\\n\\n“If you’re talking about humanitarianism, famine, the wars — really, other than natural causes, war is the No. 1 cause of famine\\naround the world,” Senator Rand Paul, Republican of Kentucky, told Ms. Power last month during her Senate confirmation hearing.\\n“Are you willing to admit that the Libyan and Syrian interventions that you advocated for were a mistake?”\\n\\nMs. Power did not. “When these situations arise, it’s a question almost of lesser evils — that the choices are very challenging,” she\\nsaid.\\n\\nBy its very nature, the U.S. aid agency takes a long-term view of the world compared with the immediacy of military action. Beyond\\nthe roughly $6 billion in humanitarian aid it is delivering this year to disaster-ridden nations, the agency seeks to prevent conflict at\\nits roots, largely bolstering economies, countering state corruption and fostering democracy and human rights.\\n\\nThat mission is central to Mr. Biden’s foreign policy, and will perhaps prove nowhere more pivotal than in his global competition\\nwith China.\\n\\nLast month, Secretary of State Antony J. Blinken assured allies that they would not be backed into an “‘us-or-them’ choice with\\nChina” as the two superpowers vie for economic, diplomatic and military advantage.\\n\"\r\n[2] \"                                Secretary of State Antony J. Blinken at the opening session of talks with China at the\\n                                Captain Cook hotel in Anchorage. Pool photo by Frederic J. Brown\\n\\n\\n\\nInstead, the United States is highlighting what officials call China’s malign ideology and self-interests as it expands an influence\\ncampaign across Africa, Europe and South America with financial loans, infrastructure funds, coronavirus vaccines and advanced\\ntechnology.\\n\\nThe Trump administration also seized on China’s human rights abuses — particularly against ethnic Uyghurs in the country’s\\nwestern region of Xinjiang — to persuade allies to turn against Beijing. On the Trump administration’s final day in office, Mike\\nPompeo, the secretary of state, declared China’s oppression against Uyghurs as an act of genocide, and he criticized Beijing’s\\nviolent suppression of dissidents in Hong Kong and military harassment of Taiwan.\\n\\n\\n                                Sign Up for On Politics A guide to the political news cycle, cutting\\n                                through the spin and delivering clarity from the chaos. Get it sent to your\\n                                inbox.\\n\\n\\nOfficials said China’s much-debated Belt and Road Initiative was a prime battleground for U.S.A.I.D. to challenge Beijing.\\n\\nRepresentative Tom Malinowski, Democrat of New Jersey and a former assistant secretary of state for democracy and human\\nrights for Mr. Obama, described a “perception that China is exporting corruption” with its loans and development projects.\\n\\nFor example, a study in February by the International Republican Institute, a private nonprofit group that receives government\\nfunding and promotes democracy, concluded that Panama’s decision in 2017 to sever diplomatic ties with Taiwan “appears to have\\nbeen driven by payoffs” from China. It also noted that Nepal regularly revoked the legal status of Tibetan refugees after becoming\\neconomically reliant on Beijing.\\n\\nThe American aid agency alone cannot match the funds that China has seeded in developing countries. But Mr. Malinowski said its\\nsupport to journalists, legal advisers and legitimate opposition groups could “expose and combat” corrosive foreign leaders who\\nhad benefited from Beijing’s financial backing and playbook for how to remain in power.\\n\\n“There is one issue that has risen to the top in this administration that I know she is very focused on, and that’s fighting corruption,”\\nMr. Malinowski said of Ms. Power. “And U.S.A.I.D. has a very important role to play there, potentially.”\\n\\nAt her confirmation hearing in March, Ms. Power told senators she was moved to pursue a career in foreign policy after the 1989\\nmassacre of protesters in Tiananmen Square in Beijing. She described China’s “coercive and predatory approach, which is so\\ntransactional” in its dealings with developing countries that ultimately become dependent on Beijing through what she called “debt-\\ntrap diplomacy.”\\n\\n“I think it’s not going over that well, and that creates an opening for the United States,” Ms. Power told Senator Todd Young,\\nRepublican of Indiana.\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \r\n[3] \"The mostly benign prodding by Democrats and Republicans during the hearing signaled how countering China has become a rare,\\nif reliable, issue of bipartisanship in Congress. “It’s absolutely essential that our development dollars, I think, be used to advance\\nour geostrategic priorities,” Mr. Young said.\\n\\nThe aid agency and the State Department have budgeted about $2 billion on programs to foster democracy, human rights and open\\ngovernance abroad in the 2021 fiscal year — one-third as much as funding for humanitarian assistance.\\n\\nIt is an area that Ms. Power is expected to expand. The Biden administration’s first budget blueprint, released on Friday, asserted it\\nwould commit an unspecified but “significant increase in resources” to advance human rights and democracy while thwarting\\ncorruption and authoritarianism.\\n\\n\\n\\n\\n                               Asylum seekers from Central America crossing the Paso del Norte International Bridge,\\n                               in Ciudad Juarez, Mexico. One of Ms. Power’s priorities will be to target corruption,\\n                               violence and poverty in the region. Jose Luis Gonzalez/Reuters\\n\\n\\n\\nThe spending plan also will support another of Ms. Power’s priorities: targeting corruption, violence and poverty in Central\\nAmerica as a means to curb the flow of thousands of migrants who head to the southwestern border each year. The Biden\\nadministration is banking on a $4 billion strategy through 2025 — including an initial tranche of $861 million proposed this year — to\\nhelp stabilize the region.\\n\\nIn El Salvador, for example, homicides dropped 61 percent after a U.S.A.I.D. effort to reduce violence from 2015 to 2017, Ms. Power\\ntold the senators, and the agency’s programs in Honduras have yielded similar results. The programs not only supported local\\nprosecutors but also brought together government officials, businesses and church and community leaders to divert young people\\nfrom gangs through job training, tutoring and artistic activities.\\n\\nShe was met with some skepticism.\\n\\nSenator Rob Portman, Republican of Ohio, noted that the number of children from Central America at the border had steadily\\nincreased since January, even though the United States spent $3.6 billion over the past five years on similar efforts.\\n\\n“The results are not impressive,” Mr. Portman said. “It’s an economic issue, primarily,” and “people will still be looking to come to\\nthe United States.”\\n\\nExplaining foreign policy decisions to the American people, and making it relevant to their lives, is a driving theme of the State\\nDepartment under Mr. Biden. Ms. Power can reach back to her own experiences as both an immigrant from Ireland and a\\nstoryteller to make the case for easing the border crisis by attacking its root causes.\\n\\n“That’s part of the job, too — you’ve got to be a salesperson, you’ve got to go out there and explain to people, ‘Here’s why we need\\nmore resources to do this work, and here’s where U.S.A.I.D. can be an incredibly important partner,’” said John Prendergast, a\\nlongtime human rights and anticorruption activist and close friend to Ms. Power.\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \r\n[4] \"“There is so much that can be done between bombing and nothing,” Mr. Prendergast said, paraphrasing Luis Moreno Ocampo, the\\nformer prosector of the International Criminal Court who was featured in the same documentary about genocide as Ms. Power.\\n“And Samantha’s whole work and life has been between those two extremes.”\\n\\nGayle Smith, who ran the aid agency for Mr. Obama and is now the State Department’s coronavirus vaccine envoy, put it more\\nbluntly.\\n\\n“It’s not like U.S.A.I.D. is going to invade somebody,” she said.\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \r\n\r\nInspecting Individual\r\nArticles\r\nNow I’m going to use “purrr” to “pluck()” each of the articles as\r\nits’ own vector and create a corpus of each article to examine.\r\n\r\n\r\narticle_111 <- nyt_articles %>% \r\n  pluck(1)\r\narticle_111 <- as_vector(article_111)\r\n\r\narticle_111_corpus <- corpus(article_111)\r\narticle_111_summary <- summary(article_111_corpus)\r\narticle_111_summary\r\n\r\n\r\nCorpus consisting of 4 documents, showing 4 documents:\r\n\r\n  Text Types Tokens Sentences\r\n text1   357    688        24\r\n text2   289    523        19\r\n text3   304    562        18\r\n text4    76    105         4\r\n\r\nI also found a very interesting way to pul the text and save them as\r\nindividual .txt files, but for now I’m just going to note that as an\r\nalternative process. I’ve struggled quite a bit to get the PDF text read\r\ncompared to the headlines.\r\n\r\n\r\nShow code\r\n\r\nconvertpdf2txt <- function(dirpath){\r\n  files <- list.files(dirpath, full.names = T)\r\n  x <- sapply(files, function(x){\r\n  x <- pdftools::pdf_text(x) %>%\r\n  paste(sep = \" \") %>%\r\n  stringr::str_replace_all(fixed(\"\\n\"), \" \") %>%\r\n  stringr::str_replace_all(fixed(\"\\r\"), \" \") %>%\r\n  stringr::str_replace_all(fixed(\"\\t\"), \" \") %>%\r\n  stringr::str_replace_all(fixed(\"\\\"\"), \" \") %>%\r\n  paste(sep = \" \", collapse = \" \") %>%\r\n  stringr::str_squish() %>%\r\n  stringr::str_replace_all(\"- \", \"\") \r\n  return(x)\r\n    })\r\n}\r\n# apply function\r\ntxts <- convertpdf2txt(\"./files\")\r\n# inspect the structure of the txts element\r\nstr(txts)\r\n\r\n\r\n Named chr [1:10] \"https://www.nytimes.com/2021/04/13/us/politics/samantha-power-biden.html After Backing Military Force in Past, \"| __truncated__ ...\r\n - attr(*, \"names\")= chr [1:10] \"./files/article_111.pdf\" \"./files/article_132.pdf\" \"./files/article_193.pdf\" \"./files/article_196.pdf\" ...\r\n\r\n\r\n\r\nShow code\r\n\r\n#apply length functions\r\nlapply(txts, length)\r\n\r\n\r\n$`./files/article_111.pdf`\r\n[1] 1\r\n\r\n$`./files/article_132.pdf`\r\n[1] 1\r\n\r\n$`./files/article_193.pdf`\r\n[1] 1\r\n\r\n$`./files/article_196.pdf`\r\n[1] 1\r\n\r\n$`./files/article_278.pdf`\r\n[1] 1\r\n\r\n$`./files/article_288.pdf`\r\n[1] 1\r\n\r\n$`./files/article_293.pdf`\r\n[1] 1\r\n\r\n$`./files/article_300.pdf`\r\n[1] 1\r\n\r\n$`./files/article_56.pdf`\r\n[1] 1\r\n\r\n$`./files/article_7.pdf`\r\n[1] 1\r\n\r\nShow code\r\n\r\n#view the structure of the list\r\nstr(txts)\r\n\r\n\r\n Named chr [1:10] \"https://www.nytimes.com/2021/04/13/us/politics/samantha-power-biden.html After Backing Military Force in Past, \"| __truncated__ ...\r\n - attr(*, \"names\")= chr [1:10] \"./files/article_111.pdf\" \"./files/article_132.pdf\" \"./files/article_193.pdf\" \"./files/article_196.pdf\" ...\r\n\r\nShow code\r\n\r\n# add names to txt files\r\nnames(txts) <- paste(\"nyt\", 1:length(txts), sep = \"\")\r\n# save result to disc\r\nlapply(seq_along(txts), function(i)writeLines(text = unlist(txts[i]),\r\n    con = paste(\"./txts\", names(txts)[i],\".txt\", sep = \"\")))\r\n\r\n\r\n[[1]]\r\nNULL\r\n\r\n[[2]]\r\nNULL\r\n\r\n[[3]]\r\nNULL\r\n\r\n[[4]]\r\nNULL\r\n\r\n[[5]]\r\nNULL\r\n\r\n[[6]]\r\nNULL\r\n\r\n[[7]]\r\nNULL\r\n\r\n[[8]]\r\nNULL\r\n\r\n[[9]]\r\nNULL\r\n\r\n[[10]]\r\nNULL\r\n\r\nUnlist\r\nDocumenting, for now, the ways I’m struggling with so I can find out\r\nwhy.\r\n\r\n\r\n#convert list to vector\r\n#nyt_vector <- unlist(nyt_articles, recursive = TRUE)\r\n#put articles into data frame\r\n#nyt_df <- as.data.frame(nyt_vector, row.names = NULL, stringsAsFactors = FALSE)\r\n\r\n\r\n\r\n\r\n\r\n#create corpus\r\n#nyt_corpus <- corpus(txts)\r\n#confirming class of corpus\r\n#class(nyt_corpus)\r\n#confirm length of corpus\r\n#length(nyt_corpus)\r\n\r\n\r\n\r\nCreate Term Document Matrix\r\n\r\n\r\n#using the tm package\r\n#nyt_tdm <- TermDocumentMatrix(nyt_corpus, \r\n                                   #control = \r\n                                     #list(removePunctuation = TRUE,\r\n                                          #stopwords = TRUE,\r\n                                          #tolower = TRUE,\r\n                                          #stemming = FALSE,\r\n                                          #removeNumbers = TRUE,\r\n                                          #bounds = list(global = c(3, Inf))))\r\n\r\n\r\n\r\nInspect TDM\r\n\r\n\r\n#inspect\r\n#inspect(nyt_tdm)\r\n\r\n\r\n\r\nFrequent Terms\r\nThe “findFreqTerms()” using the “tm” package to find the frequently\r\noccurring terms, starting with a frequency threshold of 20:\r\n\r\n\r\n#words that occur at least 10 times\r\n#findFreqTerms(nyt_tdm, lowfreq = 20, highfreq = Inf)\r\n\r\n\r\n\r\nReturn Results in a Data\r\nFrame\r\nI’ll save the result and use it to subset the TDM as “ft”, “frequent\r\nterms”.\r\nLooking at the top frequency words in decreasing order, I can beging\r\nto get a feel for what questions I need to be ready to ask next.\r\n\r\n\r\n#keep the terms with at least 20 minimum frequency\r\n#ft <- findFreqTerms(nyt_tdm, lowfreq = 20, highfreq = Inf)\r\n#nyt_tdm_ft <- as.matrix(nyt_tdm[ft,])\r\n#sort(apply(nyt_tdm_ft, 1, sum), decreasing = TRUE)\r\n\r\n\r\n\r\nGenerate Document-Feature\r\nMatrix\r\n\r\n\r\nShow code\r\n\r\n#library(quanteda.dictionaries)\r\n#library(quanteda.sentiment)\r\n\r\n\r\n\r\n\r\n\r\n# Ensure the column names are appropriate for use in an R model\r\n#colnames(articles_tdm) <- make.names(colnames(articles_tdm)) \r\n\r\n\r\n\r\n\r\n\r\n#use liwcalike() to estimate sentiment using NRC dictionary\r\n#nyt_nrc <- liwcalike(as.character(nyt_corpus), data_dictionary_NRC)\r\n#names(nyt_nrc)\r\n\r\n\r\n\r\nTerms & Frequencies\r\nI want to get a sense of my terms and frequencies, so I’ll look at\r\nthe terms using the “stringr” package.\r\nFor example, it looks like the word “veteran” appears in 86 of the\r\ndocuments with a word count of 210.\r\n\r\n\r\n#sum(str_detect(nyt_articles, \"veteran\"))\r\n#sum(str_count(nyt_corpus, \"veteran\"))\r\n\r\n\r\n\r\nPreprocessing Choices\r\nRefining further using the “stemming” option, and running the tdm()\r\nfunction, the sparsity remains —, with —– terms as compared to —– in the\r\nun-stemmed version.\r\nAlternative Processing\r\n\r\n\r\n\r\nThe problems is that stemming removes too many of the words I’ll want\r\nto examine for sentiment analysis, so I will not use that option at this\r\ntime.\r\nTokenization\r\nI finally realized how to remove the “�” symbol that has plagued me\r\nsince starting working with this API by using “remove_symbols=TRUE” in\r\naddition to removing the punctuation when tokenizing:\r\n\r\n\r\nShow code\r\n\r\n#nyt_tokens <- tokens(nyt_corpus,\r\n                   #remove_punct = TRUE,\r\n                   #remove_symbols = TRUE)\r\n#nyt_tokens\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-04-23T12:32:02-05:00",
    "input_file": "pdf-analysis.knit.md"
  },
  {
    "path": "posts/welcome/",
    "title": "Analysis of New York Times Headlines",
    "description": "This is the project page for the analysis of differences between main and print headlines for New York Times articles published surrounding the U.S. withdrawal of the military in Afghanistan.",
    "author": [
      {
        "name": "Kristina Becvar",
        "url": "https://kbec19.github.io/Grateful-Network/"
      }
    ],
    "date": "2022-04-13",
    "categories": [],
    "contents": "\r\n\r\nFor this project, I am using some data gathered in the DACSS 602\r\ncourse “Research Design”.\r\nI continued down the same path but with new data and a new direction\r\nthrough the DACSS 697D course “Text as Data”.\r\nMore background data can be found in this series of posts from my academic blog.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-04-23T00:25:35-05:00",
    "input_file": "welcome.knit.md"
  }
]
